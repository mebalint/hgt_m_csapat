{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DH6lom8B2yYD",
        "qAemnA96qMG8",
        "scpSgHxT1lLE",
        "qhYEpdNmbEKk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mebalint/hgt_football_project/blob/main/hgt_m_csapat_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Mielőtt belevágnánk fontos megjegyzés, hogy ez a csapat nyerte a félév elején a sport szeletet, melynek átadására még nem került sor.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7OPJybwkxopw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bevezetés"
      ],
      "metadata": {
        "id": "XZ6PoDSTp1-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ez a Google Collab a Haladó Gépi Tanulás tárgy az M csapatának notebookja. Az M csapat tagjai: Matúz Máté, Mészáros Bálint, Medgyes Csaba és Oroszki Norbert. A terv kezdetleges, a rendelkezésre álló adatok, illetve Benchmark-ok függvényében változhat. Alapjáraton Sentiment Analysis-t szeretnénk vizsgálni  IMDb értékelések alapján.\n",
        "\n",
        "Az eredeti terv:\n",
        "\n",
        "- 3 hét (4-6. hét): Irodalom és a rendelkezésre álló adatok értelmezése, Benchmark-ok átnézése.\n",
        "- 1 hét (7. hét): Adatértelmezés, adattisztítás és feldogozás. \n",
        "-Esetleges újratervezés, hogyha a Sentiment Analysis nem valósítható meg.\n",
        "-4 hét (8-11. hét): Modellezés.\n",
        "-2 hét (12-13. hét): Eredmények összegzése, modell kiértékelése és tesztelése, dokumentáció elkészítése. \n",
        "\n",
        "Mivel a Sentiment Analysis kifejezetten jól sikerült, nem látjuk értelmét, hogy ezt a modellt fejlesszük, így a félév végéig egy új témát szeretnénk kidolgozni, labdarúgás eredményeit szeretnénk prediktálni. \n",
        "\n",
        "Az új projekt Notebook-ját egy másik Colab-ban található meg."
      ],
      "metadata": {
        "id": "8CI_uPASp6vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Használt csomagok:"
      ],
      "metadata": {
        "id": "DH6lom8B2yYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Először is a későbbi Python frissítések miatt a használt csomagok és függvények importálásával kezdjük. "
      ],
      "metadata": {
        "id": "1sAGBdtD2uCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalAvgPool1D"
      ],
      "metadata": {
        "id": "xgEIK4DQ3Rs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most kössük össze a Google Drive-ot ezzel a Notebook-al, hogy közösen tudjunk dolgozni. Egy pop-up fel fog ugrani."
      ],
      "metadata": {
        "id": "WpfuhPqA1Tde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-cAj7Mi1iIY",
        "outputId": "ad880316-f583-42fc-e441-e7531d9b0386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eredmények:"
      ],
      "metadata": {
        "id": "qAemnA96qMG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Sentiment Analysis eredménye:\n",
        "- Loss: $0.1116$\n",
        "- Accuracy: $0.9620$ \n",
        "- Val_loss: $0.4210$\n",
        "- Val_accuracy: $0.8761$\n",
        "\n",
        "Ebbe már nem szereténk több időt befektetni, ezzel az eredménnyel teljes mértékben kiegyezünk."
      ],
      "metadata": {
        "id": "N97TIEy1pB0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDb adathalmazon Sentiment Analysis:"
      ],
      "metadata": {
        "id": "scpSgHxT1lLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Az adat az alábbi (nyilvános) linken megtekinthető: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/metadata?fbclid=IwAR1jviGz_kIpD87PoL23WxaPrtNW8B84E0Zuf3aw6DnIvcaw-rcWSoXUWgU Először az en_core_web_sm modellt vizsgáljuk."
      ],
      "metadata": {
        "id": "RxWbivR812oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_current = '/content/drive/MyDrive/HGT M csapat'\n",
        "\n",
        "os.chdir(path_current)\n",
        "\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        " \n",
        "#en_core_web_sm, this is the small english pipeline optimized for CPU. Small language model in short. "
      ],
      "metadata": {
        "id": "mDQH2zc13ofU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Címkézzük az adatokat, 1-et írjunk pozitív esetben (dokumentáció: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
      ],
      "metadata": {
        "id": "7Wy31wk15kb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment']) \n",
        "\n",
        "# transformed column in space, output 0-s,1-s\n",
        "# LabelEncoder fitted itself, found the unique values, and encoded them from 0,1,2,3.... now only 0,1."
      ],
      "metadata": {
        "id": "s8hFgd9XrhaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mivel értelmes dolgot szeretnénk visszakapni így az attribútumok után kell _ karakter."
      ],
      "metadata": {
        "id": "KVLvxzeQ6Zpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(le.classes_)"
      ],
      "metadata": {
        "id": "fgU0Wre0rlVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c5f615-af0f-4641-b797-fbdb3383f3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transzformáljuk és formázzuk a sztringeket, szabaduljunk meg a HTML tag-ektől stb. Példának nézzük az elsőt:"
      ],
      "metadata": {
        "id": "irQvlVHN6m93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][1]"
      ],
      "metadata": {
        "id": "WT676W4Urom8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2059681f-6cfa-4e84-87ff-620c44209e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.analyze_pipes() # We can see here the pipes our doc flows through"
      ],
      "metadata": {
        "id": "rfCK68UOrr__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d7e096-ed07-4477-80d6-4269fa7913b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'tagger': {'assigns': ['token.tag'],\n",
              "   'requires': [],\n",
              "   'scores': ['tag_acc'],\n",
              "   'retokenizes': False},\n",
              "  'parser': {'assigns': ['token.dep',\n",
              "    'token.head',\n",
              "    'token.is_sent_start',\n",
              "    'doc.sents'],\n",
              "   'requires': [],\n",
              "   'scores': ['dep_uas',\n",
              "    'dep_las',\n",
              "    'dep_las_per_type',\n",
              "    'sents_p',\n",
              "    'sents_r',\n",
              "    'sents_f'],\n",
              "   'retokenizes': False},\n",
              "  'attribute_ruler': {'assigns': [],\n",
              "   'requires': [],\n",
              "   'scores': [],\n",
              "   'retokenizes': False},\n",
              "  'lemmatizer': {'assigns': ['token.lemma'],\n",
              "   'requires': [],\n",
              "   'scores': ['lemma_acc'],\n",
              "   'retokenizes': False},\n",
              "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
              "   'requires': [],\n",
              "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
              "   'retokenizes': False}},\n",
              " 'problems': {'tok2vec': [],\n",
              "  'tagger': [],\n",
              "  'parser': [],\n",
              "  'attribute_ruler': [],\n",
              "  'lemmatizer': [],\n",
              "  'ner': []},\n",
              " 'attrs': {'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
              "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
              "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
              "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
              "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
              "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
              "  'doc.sents': {'assigns': ['parser'], 'requires': []}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mivel ez csúnya transzformájunk:"
      ],
      "metadata": {
        "id": "4NO5giTB65bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(lambda x:x.replace('<br /><br />', ''))\n",
        "df['review'] = df['review'].apply(lambda x:x.replace('..', ''))\n",
        "df['review'] = df['review'].apply(lambda x:x.replace('...', ''))\n",
        "df['review'] = df['review'].apply(lambda x:x.replace('....', ''))"
      ],
      "metadata": {
        "id": "mMWFOwdlruME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most csak a tokenizáló lépést csináljuk, Punctuation metódussal. Ez minden ASCII karaktert kigyűjt. (https://docs.python.org/3/library/string.html)"
      ],
      "metadata": {
        "id": "Vb_ffSKV7KE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punct = string.punctuation # List of all punctuation characters. \n",
        "\n",
        "def tokenizer_f(x): # We give it a dataframe. Or a row of a dataframe. \n",
        "    sent = nlp(x) # Creates a spacy doc object by running it through the pipeline\n",
        "    token = []\n",
        "    for i in (sent): # We iterate through the third biggest container in spacy the tokens.\n",
        "        if not i.is_stop and not i.lemma_.lower() in punct: # Ha nincs stopwords-ben és nem punctutation.\n",
        "            token.append(i.lemma_.lower())          \n",
        "    return ' '.join(token) # megszépítve összerakjuk újra. \n",
        "\n",
        "# if i.lemma_ == '-PRON-': # Spacy_v2-ben ez még '-PRON-' volt. \n",
        "#    token.append(i.lower_)"
      ],
      "metadata": {
        "id": "119AnSDDrywn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = []\n",
        "for i in tqdm(range(df.shape[0])):\n",
        "    review.append(tokenizer_f(df['review'][i]))\n",
        "\n",
        "# %store review Ezt érdemes lementeni 31 percig töltött. "
      ],
      "metadata": {
        "id": "lodEJxQzr8jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35026fb9-cb5e-4245-982d-6b9f2e2a642b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [38:18<00:00, 21.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(review)\n",
        "y = df['sentiment'].values"
      ],
      "metadata": {
        "id": "7rXe4REOsG6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X)"
      ],
      "metadata": {
        "id": "MHKTmkFrsK7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2e4026-42f1-417b-a2e5-b2845e72fa13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "zHFzSKaWsNAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89385000-a2aa-4e87-86d3-8bdf4dc1aa1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33500,), (16500,), (33500,), (16500,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000,oov_token=\"<00v>\")\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=400)\n",
        "X_test = pad_sequences(X_test, maxlen=400)"
      ],
      "metadata": {
        "id": "CxGLR2PnsXol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = 10000, output_dim = 15,input_length = 400))\n",
        "model.add(GlobalAvgPool1D())\n",
        "model.add(Dense(15, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(2, activation = 'softmax'))\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)"
      ],
      "metadata": {
        "id": "LntDFUySsYtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24dbfa6-a577-491c-e0fb-6400f3af2dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1047/1047 - 8s - loss: 0.4705 - accuracy: 0.7713 - val_loss: 0.2935 - val_accuracy: 0.8868 - 8s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "1047/1047 - 6s - loss: 0.2484 - accuracy: 0.9048 - val_loss: 0.2799 - val_accuracy: 0.8906 - 6s/epoch - 6ms/step\n",
            "Epoch 3/10\n",
            "1047/1047 - 7s - loss: 0.2090 - accuracy: 0.9210 - val_loss: 0.2883 - val_accuracy: 0.8876 - 7s/epoch - 6ms/step\n",
            "Epoch 4/10\n",
            "1047/1047 - 6s - loss: 0.1844 - accuracy: 0.9321 - val_loss: 0.2982 - val_accuracy: 0.8885 - 6s/epoch - 6ms/step\n",
            "Epoch 5/10\n",
            "1047/1047 - 6s - loss: 0.1678 - accuracy: 0.9380 - val_loss: 0.3084 - val_accuracy: 0.8886 - 6s/epoch - 6ms/step\n",
            "Epoch 6/10\n",
            "1047/1047 - 6s - loss: 0.1543 - accuracy: 0.9429 - val_loss: 0.3284 - val_accuracy: 0.8847 - 6s/epoch - 6ms/step\n",
            "Epoch 7/10\n",
            "1047/1047 - 6s - loss: 0.1415 - accuracy: 0.9491 - val_loss: 0.3681 - val_accuracy: 0.8745 - 6s/epoch - 6ms/step\n",
            "Epoch 8/10\n",
            "1047/1047 - 6s - loss: 0.1312 - accuracy: 0.9535 - val_loss: 0.3626 - val_accuracy: 0.8815 - 6s/epoch - 6ms/step\n",
            "Epoch 9/10\n",
            "1047/1047 - 6s - loss: 0.1202 - accuracy: 0.9592 - val_loss: 0.3885 - val_accuracy: 0.8790 - 6s/epoch - 6ms/step\n",
            "Epoch 10/10\n",
            "1047/1047 - 6s - loss: 0.1116 - accuracy: 0.9620 - val_loss: 0.4210 - val_accuracy: 0.8761 - 6s/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faefd6fc790>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}